import pandas as pd
import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
import sys

# Gestion professionnelle des d√©pendances optionnelles
try:
    from textblob import TextBlob
    NLP_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è Attention : 'textblob' n'est pas install√©. L'analyse de sentiment sera ignor√©e.")
    print("   -> Installez-le via : pip install textblob")
    NLP_AVAILABLE = False

# =================CONFIGURATION=================
INPUT_FILE = "raw_prisoner_data.parquet"
OUTPUT_FILE = "clean_prisoner_dataset.parquet"

def load_data(filepath):
    print(f"üì• Chargement de {filepath}...")
    try:
        df = pd.read_parquet(filepath)
        # Tri indispensable pour que le calcul de m√©moire (shift) fonctionne chronologiquement
        df = df.sort_values(by=['match_id', 'round_num'])
        return df
    except Exception as e:
        print(f"‚ùå Erreur critique de chargement : {e}")
        return pd.DataFrame()

def get_sentiment_score(text):
    """
    Fonction Helper NLP.
    Retourne un score de polarit√© : -1 (Tr√®s N√©gatif) √† +1 (Tr√®s Positif).
    Retourne 0.0 si neutre ou vide.
    """
    if not isinstance(text, str) or not text.strip():
        return 0.0
    try:
        return TextBlob(text).sentiment.polarity
    except Exception:
        return 0.0

def feature_engineering(df):
    """
    Cr√©ation des colonnes d√©riv√©es (Niveau Senior).
    Int√®gre : Lag Features, Psychologie comportementale et NLP.
    """
    print("‚öôÔ∏è Enrichissement des donn√©es (Feature Engineering)...")
    
    # --- 1. CONVERSION NUM√âRIQUE ---
    # Binarisation des choix (C=1, T=0) pour les calculs statistiques
    df['p1_is_coop'] = (df['p1_move'] == 'C').astype(int)
    df['p2_is_coop'] = (df['p2_move'] == 'C').astype(int)
    
    # --- 2. M√âMOIRE (LAG FEATURES) ---
    # On regarde ce qu'il s'est pass√© au tour T-1 (Shift)
    # Le groupby('match_id') emp√™che de m√©langer les parties entre elles
    df['p1_prev_move'] = df.groupby('match_id')['p1_move'].shift(1).fillna("START")
    df['p2_prev_move'] = df.groupby('match_id')['p2_move'].shift(1).fillna("START")
    
    # --- 3. √âTAT PSYCHOLOGIQUE (CONTEXTUALISATION) ---
    # Coop√©ration Mutuelle (CC) : Confiance / Paix
    df['is_mutual_coop'] = ((df['p1_move'] == 'C') & (df['p2_move'] == 'C')).astype(int)
    
    # Trahison Subie par P1 (P1=C, P2=T) -> P1 est le "Dindon de la farce" (Sucker)
    df['p1_betrayed'] = ((df['p1_move'] == 'C') & (df['p2_move'] == 'T')).astype(int)
    
    # Trahison Inflig√©e par P1 (P1=T, P2=C) -> P1 est l'"Exploiteur"
    df['p1_exploits'] = ((df['p1_move'] == 'T') & (df['p2_move'] == 'C')).astype(int)
    
    # Conflit Mutuel (TT) -> Guerre / Punition
    df['is_mutual_defect'] = ((df['p1_move'] == 'T') & (df['p2_move'] == 'T')).astype(int)

    # --- 4. KPIs PERFORMANCE (CUMULATIFS) ---
    # Score Cumul√© (Running Total) pour voir la "Course aux points"
    df['p1_cum_score'] = df.groupby('match_id')['p1_score'].cumsum()
    df['p2_cum_score'] = df.groupby('match_id')['p2_score'].cumsum()

    # Taux de Coop√©ration Glissant (√âvolution de la gentillesse)
    df['p1_rolling_coop'] = df.groupby('match_id')['p1_is_coop'].expanding().mean().reset_index(level=0, drop=True)

    # --- 5. ANALYSE R√âACTIONNELLE ---
    # PARDON : Est-ce que je coop√®re ALORS QUE j'ai √©t√© trahi juste avant ?
    df['p1_prev_betrayed'] = ((df['p1_prev_move'] == 'C') & (df['p2_prev_move'] == 'T'))
    df['p1_forgives'] = (df['p1_prev_betrayed'] & (df['p1_move'] == 'C')).astype(int)

    # --- 6. NLP & SENTIMENT ANALYSIS (JOKER SENIOR) ---
    if NLP_AVAILABLE:
        print("üß† Ex√©cution de l'Analyse de Sentiment (NLP) sur les raisonnements...")
        # On applique la fonction sur les colonnes de texte
        # Cela permet de voir si Machiavel utilise des mots "positifs" pour masquer ses trahisons
        df['p1_sentiment'] = df['p1_reasoning'].apply(get_sentiment_score)
        df['p2_sentiment'] = df['p2_reasoning'].apply(get_sentiment_score)
    else:
        df['p1_sentiment'] = 0.0
        df['p2_sentiment'] = 0.0

    return df

def save_clean_data(df, filepath):
    # Utilisation de PyArrow pour une √©criture Parquet optimis√©e et typ√©e
    table = pa.Table.from_pandas(df)
    pq.write_table(table, filepath)
    print(f"üíæ Sauvegarde r√©ussie : {filepath}")
    print(f"üìä Dimensions finales : {df.shape[0]} lignes x {df.shape[1]} colonnes")

def quality_check_transform(df):
    """Audit rapide post-transformation pour valider l'int√©grit√©"""
    print("\n--- üîç Audit Rapide des Transformations ---")
    
    # 1. V√©rifier la M√©moire
    print("1. Test Coh√©rence M√©moire (Shift) :")
    print(df[['match_id', 'round_num', 'p1_move', 'p1_prev_move']].iloc[1:3].to_string(index=False))
    
    # 2. V√©rifier le NLP
    if 'p1_sentiment' in df.columns:
        mean_sent = df['p1_sentiment'].mean()
        print(f"2. Score de sentiment moyen global : {mean_sent:.4f} (-1=N√©gatif, +1=Positif)")
    
    # 3. V√©rifier les KPIs
    if df['p1_cum_score'].isnull().sum() == 0:
        print("‚úÖ Tous les KPIs sont calcul√©s sans erreurs (NaN).")
    else:
        print("‚ùå ALERTE : Pr√©sence de valeurs nulles dans les scores cumul√©s.")

if __name__ == "__main__":
    # Ex√©cution du Pipeline ETL - Phase 2
    df_raw = load_data(INPUT_FILE)
    
    if not df_raw.empty:
        df_clean = feature_engineering(df_raw)
        quality_check_transform(df_clean)
        save_clean_data(df_clean, OUTPUT_FILE)
